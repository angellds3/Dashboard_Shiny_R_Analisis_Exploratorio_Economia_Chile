# Viento_270001_2019_2025 <- select(Viento_270001_2019_2025, -origen)
library(dplyr)
library(lubridate)
Viento_270001_2019_2025_horaria <- Viento_270001_2019_2025 %>%
# 1) Seleccionar sólo las columnas necesarias
select(codigoNacional, momento, ddInst, ffInst) %>%
# 2) Asegurar que 'momento' es POSIXct
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
) %>%
# 3) “Pisar” cada timestamp al inicio de la hora
mutate(
momento = floor_date(momento, unit = "hour")
) %>%
# 4) Agrupar por estación y hora, y calcular promedios de ddInst y ffInst
group_by(codigoNacional, momento) %>%
summarise(
ddInst = mean(ddInst, na.rm = TRUE),
ffInst = mean(ffInst, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(Viento_270001_2019_2025_horaria)
library(dplyr)
library(lubridate)
Viento_270001_2019_2025_2horas <- Viento_270001_2019_2025 %>%
# 1) Seleccionar columnas clave
select(codigoNacional, momento, ddInst, ffInst) %>%
# 2) Convertir 'momento' a POSIXct y “pisar” al bloque de 2 horas
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "2 hours")
) %>%
# 3) Agrupar por estación y bloque de 2 h, y calcular promedios de ddInst y ffInst
group_by(codigoNacional, momento) %>%
summarise(
ddInst = mean(ddInst, na.rm = TRUE),
ffInst = mean(ffInst, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(Viento_270001_2019_2025_2horas)
library(dplyr)
library(lubridate)
Viento_270001_2019_2025_3horas <- Viento_270001_2019_2025 %>%
# 1) Seleccionar columnas clave
select(codigoNacional, momento, ddInst, ffInst) %>%
# 2) Convertir 'momento' a POSIXct y “pisar” al bloque de 3 horas
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "3 hours")
) %>%
# 3) Agrupar por estación y bloque de 3 h, y calcular promedios de ddInst y ffInst
group_by(codigoNacional, momento) %>%
summarise(
ddInst = mean(ddInst, na.rm = TRUE),
ffInst = mean(ffInst, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(Viento_270001_2019_2025_3horas)
library(dplyr)
library(lubridate)
Viento_270001_2019_2025_6horas <- Viento_270001_2019_2025 %>%
# 1) Seleccionar columnas clave
select(codigoNacional, momento, ddInst, ffInst) %>%
# 2) Convertir 'momento' a POSIXct y “pisar” al bloque de 6 horas
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "6 hours")
) %>%
# 3) Agrupar por estación y bloque de 6 h, y calcular promedios de ddInst y ffInst
group_by(codigoNacional, momento) %>%
summarise(
ddInst = mean(ddInst, na.rm = TRUE),
ffInst = mean(ffInst, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(Viento_270001_2019_2025_6horas)
library(readr)
library(dplyr)
library(purrr)
library(stringr)
# Ruta para los CSV de Rango Óptico Meteorológico
ruta <- "C:/Users/angel/Documents/ISLA_PASCUA/RANGO_OPTICO_METEOROLOGICO"
# 1) Listar los CSV semicolon-separated de la estación 270001 (_AAAAMM_RangoOpticoMeteorologico.csv)
archivos <- list.files(
path       = ruta,
pattern    = "^270001_[0-9]{6}_RangoOpticoMeteorologico\\.csv$",
full.names = TRUE
) %>%
# Filtrar solo entre enero 2019 y mayo 2025
keep(~ {
fecha_txt <- str_extract(basename(.x), "(?<=_)[0-9]{6}(?=_)")
fecha     <- as.Date(paste0(fecha_txt, "01"), "%Y%m%d")
fecha >= as.Date("2019-01-01") && fecha <= as.Date("2025-05-01")
})
# 2) Leer y concatenar todas las filas, usando ';' como separador
RangoOpticoMeteorologico_270001_2019_2025 <- archivos %>%
set_names() %>%
map_dfr(
~ read_delim(.x,
delim = ";",
locale = locale(decimal_mark = ".", encoding = "UTF-8")),
.id = "origen"
)
# (Opcional) Si tus datos usan coma como separador decimal, en lugar de punto:
# RangoOpticoMeteorologico_270001_2019_2025 <- archivos %>%
#   set_names() %>%
#   map_dfr(~ read_csv2(.x, locale = locale(encoding = "UTF-8")), .id = "origen")
# (Opcional) Eliminar la columna 'origen' si no la necesitas:
# RangoOpticoMeteorologico_270001_2019_2025 <-
#   select(RangoOpticoMeteorologico_270001_2019_2025, -origen)
library(dplyr)
library(lubridate)
RangoOpticoMeteorologico_270001_2019_2025_horaria <- RangoOpticoMeteorologico_270001_2019_2025 %>%
# 1) Seleccionar sólo las columnas necesarias
select(codigoNacional, momento, morInst) %>%
# 2) Convertir 'momento' a POSIXct si no lo está y “pisar” al inicio de la hora
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "hour")
) %>%
# 3) Agrupar por estación y hora, y calcular el promedio de morInst
group_by(codigoNacional, momento) %>%
summarise(
morInst = mean(morInst, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(RangoOpticoMeteorologico_270001_2019_2025_horaria)
library(dplyr)
library(lubridate)
RangoOpticoMeteorologico_270001_2019_2025_2horas <- RangoOpticoMeteorologico_270001_2019_2025 %>%
# 1) Seleccionar sólo las columnas necesarias
select(codigoNacional, momento, morInst) %>%
# 2) Convertir 'momento' a POSIXct si no lo está y “pisar” al bloque de 2 horas
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "2 hours")
) %>%
# 3) Agrupar por estación y bloque de 2 horas, y calcular el promedio de morInst
group_by(codigoNacional, momento) %>%
summarise(
morInst = mean(morInst, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(RangoOpticoMeteorologico_270001_2019_2025_2horas)
library(dplyr)
library(lubridate)
RangoOpticoMeteorologico_270001_2019_2025_3horas <- RangoOpticoMeteorologico_270001_2019_2025 %>%
# 1) Seleccionar sólo las columnas necesarias
select(codigoNacional, momento, morInst) %>%
# 2) Convertir 'momento' a POSIXct si no lo está y “pisar” al bloque de 3 horas
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "3 hours")
) %>%
# 3) Agrupar por estación y bloque de 3 horas, y calcular el promedio de morInst
group_by(codigoNacional, momento) %>%
summarise(
morInst = mean(morInst, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(RangoOpticoMeteorologico_270001_2019_2025_3horas)
# Agrupamiento en bloques de 6 horas
RangoOpticoMeteorologico_270001_2019_2025_6horas <- RangoOpticoMeteorologico_270001_2019_2025 %>%
select(codigoNacional, momento, morInst) %>%
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "6 hours")
) %>%
group_by(codigoNacional, momento) %>%
summarise(
morInst = mean(morInst, na.rm = TRUE),
.groups = "drop"
)
library(readr)
library(dplyr)
library(purrr)
library(stringr)
# Ruta para los CSV de visibilidad
ruta <- "C:/Users/angel/Documents/ISLA_PASCUA/VISIBILIDAD"
# 1) Listar los CSV semicolon-separated de la estación 270001 (_AAAAMM_Visibilidad.csv)
archivos <- list.files(
path       = ruta,
pattern    = "^270001_[0-9]{6}_Visibilidad\\.csv$",
full.names = TRUE
) %>%
# Filtrar solo entre enero 2019 y mayo 2025
keep(~ {
fecha_txt <- str_extract(basename(.x), "(?<=_)[0-9]{6}(?=_)")
fecha     <- as.Date(paste0(fecha_txt, "01"), "%Y%m%d")
fecha >= as.Date("2019-01-01") && fecha <= as.Date("2025-05-01")
})
# 2) Leer y concatenar todas las filas, usando ';' como separador
Visibilidad_270001_2019_2025 <- archivos %>%
set_names() %>%
map_dfr(
~ read_delim(.x,
delim = ";",
locale = locale(decimal_mark = ".", encoding = "UTF-8")),
.id = "origen"
)
# (Opcional) Si tus datos usan coma como separador decimal, en lugar de punto:
# Visibilidad_270001_2019_2025 <- archivos %>%
#   set_names() %>%
#   map_dfr(~ read_csv2(.x, locale = locale(encoding = "UTF-8")), .id = "origen")
# (Opcional) Eliminar la columna 'origen' si no la necesitas:
# Visibilidad_270001_2019_2025 <-
#   select(Visibilidad_270001_2019_2025, -origen)
library(dplyr)
library(lubridate)
Visibilidad_270001_2019_2025_horaria <- Visibilidad_270001_2019_2025 %>%
# 1) Seleccionar sólo las columnas necesarias
select(codigoNacional, momento, vis1Minuto) %>%
# 2) Asegurar que 'momento' es POSIXct y pisar al inicio de la hora
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "hour")
) %>%
# 3) Agrupar por estación y hora, y calcular el promedio de vis1Minuto
group_by(codigoNacional, momento) %>%
summarise(
vis1Minuto = mean(vis1Minuto, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(Visibilidad_270001_2019_2025_horaria)
library(dplyr)
library(lubridate)
Visibilidad_270001_2019_2025_2horas <- Visibilidad_270001_2019_2025 %>%
# 1) Seleccionar las columnas necesarias
select(codigoNacional, momento, vis1Minuto) %>%
# 2) Convertir 'momento' a POSIXct y “pisar” al bloque de 2 horas
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "2 hours")
) %>%
# 3) Agrupar por estación y bloque de 2 h, y calcular el promedio de vis1Minuto
group_by(codigoNacional, momento) %>%
summarise(
vis2Horas = mean(vis1Minuto, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(Visibilidad_270001_2019_2025_2horas)
library(dplyr)
library(lubridate)
Visibilidad_270001_2019_2025_3horas <- Visibilidad_270001_2019_2025 %>%
# 1) Seleccionar las columnas necesarias
select(codigoNacional, momento, vis1Minuto) %>%
# 2) Convertir 'momento' a POSIXct y “pisar” al bloque de 3 horas
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "3 hours")
) %>%
# 3) Agrupar por estación y bloque de 3 h, y calcular el promedio de vis1Minuto
group_by(codigoNacional, momento) %>%
summarise(
vis3Horas = mean(vis1Minuto, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(Visibilidad_270001_2019_2025_3horas)
library(dplyr)
library(lubridate)
Visibilidad_270001_2019_2025_6horas <- Visibilidad_270001_2019_2025 %>%
# 1) Seleccionar las columnas necesarias
select(codigoNacional, momento, vis1Minuto) %>%
# 2) Convertir 'momento' a POSIXct y “pisar” al bloque de 6 horas
mutate(
momento = as.POSIXct(momento, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
momento = floor_date(momento, unit = "6 hours")
) %>%
# 3) Agrupar por estación y bloque de 6 h, y calcular el promedio de vis1Minuto
group_by(codigoNacional, momento) %>%
summarise(
vis6Horas = mean(vis1Minuto, na.rm = TRUE),
.groups = "drop"
)
# Vista previa
head(Visibilidad_270001_2019_2025_6horas)
library(dplyr)
library(purrr)
# Lista de data.frames agregados cada 1 hora
dfs_1h <- list(
Agua   = Agua_Caida_270001_2019_2025_horaria,
Temp   = Temperatura_270001_2019_2025_horaria,
PH     = PresionHumedad_270001_2019_2025_horaria,
Viento = Viento_270001_2019_2025_horaria,
Optico = RangoOpticoMeteorologico_270001_2019_2025_horaria,
Visib  = Visibilidad_270001_2019_2025_horaria
)
# Unir todas por codigoNacional y momento
Isla_Pascua_1_Horas <- reduce(
dfs_1h,
full_join,
by = c("codigoNacional", "momento")
)
# Verificar la estructura de la tabla resultante
glimpse(Isla_Pascua_1_Horas)
# Instalar y cargar writexl (si no lo tienes)
# install.packages("writexl")
library(writexl)
# Exportar a Excel con el nombre solicitado
write_xlsx(
Isla_Pascua_1_Horas,
path = "C:/Users/angel/Documents/ISLA_PASCUA/Isla_Pascua_Meteorologia_1Horas.xlsx"
)
library(dplyr)
library(purrr)
# Lista de data.frames agregados cada 2 horas
dfs_2h <- list(
Agua   = Agua_Caida_270001_2019_2025_2horas,
Temp   = Temperatura_270001_2019_2025_2horas,
PH     = PresionHumedad_270001_2019_2025_2horas,
Viento = Viento_270001_2019_2025_2horas,
Optico = RangoOpticoMeteorologico_270001_2019_2025_2horas,
Visib  = Visibilidad_270001_2019_2025_2horas
)
# Unir todas por codigoNacional y momento
Isla_Pascua_2_Horas <- reduce(
dfs_2h,
full_join,
by = c("codigoNacional", "momento")
)
# Verifica la estructura
glimpse(Isla_Pascua_2_Horas)
# Instalar y cargar writexl (si no lo tienes)
# install.packages("writexl")
library(writexl)
# Exportar a Excel con el nombre solicitado
write_xlsx(
Isla_Pascua_2_Horas,
path = "C:/Users/angel/Documents/ISLA_PASCUA/Isla_Pascua_Meteorologia_2Horas.xlsx"
)
library(dplyr)
library(purrr)
# Lista de data.frames agregados cada 3 horas
dfs_3h <- list(
Agua   = Agua_Caida_270001_2019_2025_3horas,
Temp   = Temperatura_270001_2019_2025_3horas,
PH     = PresionHumedad_270001_2019_2025_3horas,
Viento = Viento_270001_2019_2025_3horas,
Optico = RangoOpticoMeteorologico_270001_2019_2025_3horas,
Visib  = Visibilidad_270001_2019_2025_3horas
)
# Unir todas por codigoNacional y momento
Isla_Pascua_3_Horas <- reduce(
dfs_3h,
full_join,
by = c("codigoNacional", "momento")
)
# Verifica la estructura de la tabla resultante
glimpse(Isla_Pascua_3_Horas)
# Instalar y cargar writexl (si no lo tienes)
# install.packages("writexl")
library(writexl)
# Exportar a Excel con el nombre solicitado
write_xlsx(
Isla_Pascua_3_Horas,
path = "C:/Users/angel/Documents/ISLA_PASCUA/Isla_Pascua_Meteorologia_3Horas.xlsx"
)
library(dplyr)
library(purrr)
# Lista de data.frames a unir
dfs_6h <- list(
Agua   = Agua_Caida_270001_2019_2025_6horas,
Temp   = Temperatura_270001_2019_2025_6horas,
PH     = PresionHumedad_270001_2019_2025_6horas,
Viento = Viento_270001_2019_2025_6horas,
Optico = RangoOpticoMeteorologico_270001_2019_2025_6horas,
Visib  = Visibilidad_270001_2019_2025_6horas,
Nubosidad = Nubosidad_270001_2019_2025_6horas
)
# Unir todas por codigoNacional + momento
Isla_Pascua_6_Horas <- reduce(
dfs_6h,
full_join,
by = c("codigoNacional", "momento")
)
library(dplyr)
library(lubridate)
library(stringr)
# Vector con nombres de meses en español
meses <- c(
"Enero", "Febrero", "Marzo", "Abril", "Mayo", "Junio",
"Julio", "Agosto", "Septiembre", "Octubre", "Noviembre", "Diciembre"
)
Isla_Pascua_6_Horas <- Isla_Pascua_6_Horas %>%
mutate(
# Eliminar espacios extra y convertir a POSIXct
momento = dmy_hms(str_squish(momento), tz = "UTC"),
# Extraer número de mes y mapear al nombre correspondiente
mes = meses[month(momento)]
)
# Vista previa
head(Isla_Pascua_6_Horas)
library(dplyr)
library(lubridate)
library(stringr)
Isla_Pascua_6_Horas <- Isla_Pascua_6_Horas %>%
# Asegurarnos de que 'momento' es POSIXct si viene como cadena
mutate(
momento = dmy_hms(str_squish(momento), tz = "UTC")
) %>%
# Crear un código numérico mes-día para comparar fácilmente
mutate(
mmdd = month(momento) * 100 + day(momento),
estacion = case_when(
mmdd >= 1221 | mmdd <  321 ~ "Verano",
mmdd >=  321 & mmdd <  621 ~ "Otoño",
mmdd >=  621 & mmdd <  921 ~ "Invierno",
TRUE                        ~ "Primavera"
)
) %>%
select(-mmdd)
# Vista previa
head(Isla_Pascua_6_Horas)
# Verifica que cada variable aparece una sola vez
glimpse(Isla_Pascua_6_Horas)
# Instalar y cargar writexl (si no lo tienes)
# install.packages("writexl")
library(writexl)
# Exportar a Excel con el nombre solicitado
write_xlsx(
Isla_Pascua_6_Horas,
path = "C:/Users/angel/Documents/ISLA_PASCUA/Isla_Pascua_Meteorologia_6Horas.xlsx"
)
library(dplyr)
library(tidyr)
library(ggplot2)
# 1) Añadir la variable lluvia
df6h <- Isla_Pascua_6_Horas %>%
mutate(
lluvia = if_else(rr6Horas != 0, 1, 0)
)
# 2) Pivotar a formato largo (cada variable en una fila)
df_long <- df6h %>%
pivot_longer(
cols = c(ts, td, hr, qff, ddInst, ffInst, morInst, vis6Horas),
names_to  = "variable",
values_to = "valor"
)
# 3) Scatter plot de cada variable a lo largo del tiempo, coloreado por lluvia
ggplot(df_long, aes(x = momento, y = valor, color = factor(lluvia))) +
geom_point(alpha = 0.5, size = 0.8) +
facet_wrap(~ variable, scales = "free_y", ncol = 2) +
scale_color_manual(
name   = "Lluvia",
values = c("0" = "steelblue", "1" = "firebrick"),
labels = c("0" = "Sin lluvia", "1" = "Con lluvia")
) +
labs(
x = "Momento (bloques de 6h)",
y = "Valor",
title = "Series de variables meteorológicas\ncoloreadas según presencia de lluvia"
) +
theme_minimal() +
theme(
legend.position = "bottom",
strip.text      = element_text(face = "bold")
)
library(dplyr)
library(lubridate)
# Vector con nombres de meses en español
meses <- c(
"Enero", "Febrero", "Marzo", "Abril", "Mayo", "Junio",
"Julio", "Agosto", "Septiembre", "Octubre", "Noviembre", "Diciembre"
)
Isla_Pascua_6_Horas <- Isla_Pascua_6_Horas %>%
mutate(
# 1) Convertir con el formato exacto "día/mes/año hora:min:segundo"
momento = as.POSIXct(momento, format = "%d/%m/%Y %H:%M:%S", tz = "UTC"),
# 2) Extraer el número de mes y mapear al nombre
mes = meses[month(momento)]
)
# Verifica que ya no queden NAs en 'mes'
table(Isla_Pascua_6_Horas$mes, useNA = "ifany")
# 1) Limpiamos espacios redundantes con str_squish()
Isla_Pascua_6_Horas <- Isla_Pascua_6_Horas %>%
mutate(momento_clean = str_squish(momento))
# 2) Intentamos convertir con dmy_hms(), que es más tolerante
Isla_Pascua_6_Horas <- Isla_Pascua_6_Horas %>%
mutate(
momento_parsed = dmy_hms(momento_clean, tz = "UTC")
)
# 3) Veamos cuántos quedaron NA tras el parseo
sum(is.na(Isla_Pascua_6_Horas$momento_parsed))
# 4) Una vez que momento_parsed esté bien, extraemos el mes numérico
meses <- c(
"Enero", "Febrero", "Marzo", "Abril", "Mayo", "Junio",
"Julio", "Agosto", "Septiembre", "Octubre", "Noviembre", "Diciembre"
)
Isla_Pascua_6_Horas <- Isla_Pascua_6_Horas %>%
mutate(
mes = meses[month(momento_parsed)]
)
table(Isla_Pascua_6_Horas$mes, useNA = "ifany")
View(Isla_Pascua_6_Horas)
save.image("~/datapascua.RData")
save.image("~/pscua.RData")
View(Isla_Pascua_6_Horas)
library(shiny); runApp('C:/Users/angel/Desktop/UNIVERSIDAD/Base de datos Análisis de la Relación entre Inflación, Desempleo, Variación del Dólar y Crecimiento Económico en Chile/Dashboard_Variacion_Dolar.R')
runApp('C:/Users/angel/Desktop/UNIVERSIDAD/Base de datos Análisis de la Relación entre Inflación, Desempleo, Variación del Dólar y Crecimiento Económico en Chile/1Dashboard_Variacion_Dolar.R')
runApp('C:/Users/angel/Desktop/UNIVERSIDAD/Base de datos Análisis de la Relación entre Inflación, Desempleo, Variación del Dólar y Crecimiento Económico en Chile/1Dashboard_Variacion_Dolar.R')
runApp('C:/Users/angel/Desktop/UNIVERSIDAD/Base de datos Análisis de la Relación entre Inflación, Desempleo, Variación del Dólar y Crecimiento Económico en Chile/1Dashboard_Variacion_Dolar.R')
runApp('C:/Users/angel/Desktop/UNIVERSIDAD/Base de datos Análisis de la Relación entre Inflación, Desempleo, Variación del Dólar y Crecimiento Económico en Chile/1Dashboard_Variacion_Dolar.R')
